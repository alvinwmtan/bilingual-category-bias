---
title: "Noun bias, revisited: Investigating syntactic category bias in early bilingual vocabularies"
bibliography: library.bib
csl: apa7.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Alvin Wei Ming Tan (tanawm@stanford.edu)} \\ Department of Psychology \\ Stanford University
    \AND {\large \bf Michael C. Frank} \\ Department of Psychology \\ Stanford University}
    
abstract: >
    Why are nouns often over-represented in children's early words? Prior research has suggested a range of possible explanations for the observed bias in the syntactic category composition of early vocabularies, including cognitive, linguistic, and contextual factors. In this study, we attempted to disambiguate the contributions of such factors by studying the vocabularies of children acquiring two languages. Across three analyses ($N$ = 1997), we investigated the role of different language combinations, different levels of language exposure, and different environmental contexts, finding some support for cross-linguistic modulation of syntactic category bias, as well as variation across countries. These results suggest that multiple interacting factors contribute to syntactic category biases in young children's vocabularies, and highlight the importance of understanding the broader background of the child when studying language acquisition.
    
keywords: >
    bilingualism; vocabulary; noun bias
    
output: cogsci2024::cogsci_paper
#final-submission: \cogscifinalcopy
---

```{r global_options}
#| include: FALSE
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r}
#| message: FALSE
library(tidyverse)
library(here)
library(glue)

source("scripts/analysis.R")
source("scripts/plots.R")

INTERMEDIATE_LOC <- here("intermediates")
```

# Introduction
Children's vocabularies are an important lens into the factors that shape language learning, including language input, learning environments, and cognitive biases.
One way to analyse such early vocabularies is to examine their composition in terms of syntactic categories.
Prior research has suggested that early vocabularies are dominated by words for objects, rather than words for relations; this is known as the noun bias, and has been reported for a wide range of languages [e.g., @bornsteinCrossLinguisticAnalysisVocabulary2004; @gentnerWhyNounsAre1982; see @waxmanAreNounsLearned2013 for a review].
Nonetheless, there has also been evidence suggesting that some languages exhibit no such noun bias, including Mandarin [@tardifNounsAreNot1996], Korean [@choiEarlyAcquisitionVerbs1995], and Tseltal [@casillasLittleEvidenceNoun2024] among others.
Furthermore, different studies have found conflicting results even for the same language (e.g., compare @bornsteinCrossLinguisticAnalysisVocabulary2004 and @choiEarlyAcquisitionVerbs1995 for Korean).
Considering the variation in results, there remain important theoretical questions about explanations for the occurrence of the noun bias in some (but probably not all) early vocabularies.

Hypothesised accounts for the observed noun bias fall into three broad domains.
The first domain focuses on the _cognitive_ process of word learning, proposing that nouns are easier to encode than predicates.
Gentner's [-@gentnerWhyNounsAre1982] natural partitions/relational relativity hypothesis suggests that objects are perceptually individuable (and thus easier to map to labels), whereas relations are individuated only via linguistic selection (and thus take more time to learn).
The second domain relates to _linguistic_ features affecting whether nouns or predicates are easier to learn.
Such explanations include the suggestion that, relative to predicates, nouns are more frequent in child-directed speech [e.g., @goldfieldNounBiasMaternal1993; @kimEarlyLexicalDevelopment2000], nouns are less morphologically complex [e.g., @tardifCaregiverSpeechChildrens1997], or nouns are more salient [e.g., @caselliCrosslinguisticStudyEarly1995].
Crucially, this domain seeks to account for the observed variation in the noun bias across languages, since the posited features vary across languages.
The third domain is _contextual_, suggesting that sociocultural features influence how nouns and predicates are communicated about or processed.
For example, different cultures may emphasise labels to differing extents [e.g., @choiEarlyAcquisitionVerbs1995; @tardifPuttingNounBias1999], or may have differential patterns of attention towards objects or relations [e.g., @lavinEastWestRole2006; @waxmanHowEarlyInfants2016].
Notably, these three domains of explanation are not mutually exclusive, and multiple sets of features may jointly influence the learning of words across syntactic categories.
However, it is typically difficult to distinguish between linguistic and contextual factors, since they tend to covary.

One way to disentangle linguistic and contextual factors is by studying bilingual children, who serve as a "natural experiment", since they reside within a single context while acquiring two languages; in other words, contextual factors are constant while linguistic factors vary across their two languages.
Previous research have shown that bilingual children exhibit differently sized noun biases in their two languages; this effect has been attested in English--Mandarin bilinguals [@chanPredictingTwoMandarinEnglish2010; @leveyFirstWordsProduced2003; @setohContrastingLexicalBiases2021; @xinNounVerbBias2010; @xuanLanguagespecificNounBias2013], Filipino--English bilinguals [@lucasExploringNounBias2008] and Turkish--Dutch bilinguals [@ozcanEarlyLexicalComposition2016].
The language-specific bias may depend on the specific language combination, however, as no such effect was found for a Portuguese--English bilingual child [@nicoladisEvidenceBilingualChild2001] or a German--Italian bilingual child [@klammlerSizeCompositionProductive2011]---although it should be noted that these are case studies and may not have sufficient generalisability or power.
Additionally, @chaiExtralinguisticModulationEnglish2021 has shown that bilinguals learning different language combinations (English--Mandarin vs English--Malay) can show differently sized noun biases in the common language (in this case, English), suggesting that there is some cross-linguistic influence, perhaps due to the preferential learning of translation equivalents (e.g., "dog" in English and "perro" in Spanish) [e.g., @tanRoleTranslationEquivalents2024; @tsuiAreTranslationEquivalents2022].
Different levels of language exposure have also been shown to affect noun bias sizes in Basque--Spanish bilingual children [@barnesVocabularyGrowthComposition2013].
Together, these results suggest that linguistic (and cross-linguistic) factors must play a role in explaining the noun bias, since variation across languages persists even when cognition and context are controlled for.

Surveying prior observational research on the noun bias, however, reveals another dimension of variation, namely analytic heterogeneity, which may explain some of the variance in the results obtained.
Some studies have used direct counts of the number of nouns or predicates known by a child [e.g., <!--@goldfieldNounsVerbsComprehension2000; -->@leveyFirstWordsProduced2003; <!--@lucasExploringNounBias2008; -->@ozcanEarlyLexicalComposition2016<!--; @xinNounVerbBias2010-->; @tardifCaregiverSpeechChildrens1997].
Other studies have measured nouns or predicates known as a proportion of the child's vocabulary [e.g., <!--@barnesVocabularyGrowthComposition2013; -->@bornsteinCrossLinguisticAnalysisVocabulary2004; <!--@caselliCrosslinguisticStudyEarly1995; -->@chanPredictingTwoMandarinEnglish2010; @choiEarlyAcquisitionVerbs1995<!--; @xuanLanguagespecificNounBias2013-->; @gentnerWhyNounsAre1982].
A third option is the use of a ratio---for example, the ratio of nouns to the sum of nouns and predicates [e.g., @chaiExtralinguisticModulationEnglish2021; @setohContrastingLexicalBiases2021; @tardifPuttingNounBias1999].
However, each of these three approaches is potentially affected by an availability problem: if there are more nouns than verbs that are _available_ for a child to learn, it would not be surprising for them to have more nouns in their vocabulary (whether by count, proportion, or ratio) even if they were acquiring words entirely by chance.
In other words, when evaluating whether children have tendencies to prefer learning nouns over predicates, our key metric of interest should be whether children know more nouns _than would be expected_---i.e., whether there is an _over-representation_ of nouns in the child's vocabulary.

To study the over- or under-representation of syntactic categories in early bilingual vocabularies, we adopted the approach taken by @batesDevelopmentalStylisticVariation1994 and @frankVariabilityConsistencyEarly2021. 
This approach used data from parent-report vocabulary checklists, and children's known words are expressed as proportions of the total number of words in that category on the checklist (i.e., potential opportunities for word learning).
This is then plotted against children's total vocabularies, again expressed as proportions of the total size of the checklist.
If children were to acquire words independently of their syntactic category, then we would expect their category proportions to match their total vocabulary proportions<!-----for example, if a child knows 50% of the words on the checklist, they should also know 50% of the nouns, 50% of the predicates, and 50% of the function words-->. 
Conversely, if children had a noun bias, then their noun proportions should exceed their total vocabulary proportions, suggesting an over-representation of nouns in their vocabularies. 
Such an analytic approach would thus control for the word learning opportunities that children experience overall, allowing the specific investigation of whether there are learning biases beyond mere variation in the availability of learnable words.

The present study thus employs this over-/under-representation approach to studying syntactic category biases in bilingual children, aiming to disentangle the roles of linguistic and contextual factors in shaping early vocabulary compositions.
We consider the following (mutually exclusive) alternative hypotheses regarding linguistic factors:

> H1a: The category bias is entirely cognitive in origin. Hence, individual bilingual children have same-sized category biases across their two languages.

> H1b: The category bias is affected by linguistic factors. Hence, bilingual children have different-sized category biases across their two languages. However, there is no cross-linguistic influence, so bilingual children have category biases comparable to monolinguals in each language.

> H1c: The category bias is affected by linguistic factors, and additionally can be modulated by cross-linguistic effects. Hence, for each language learnt by a bilingual child, there is a shift in category biases _away from_ monolinguals of that language, _towards_ monolinguals of the other language.

We also consider the following (mutually exclusive) alternative hypotheses regarding contextual factors:

> H2a: The category bias is not affected by contextual factors, and is only affected by universal cognitive and/or linguistic factors. Hence, bilingual children learning the same combination of languages but in different environmental contexts should have same-sized category biases.

> H2b: The category bias is affected by contextual factors. Hence, bilingual children learning the same combination of languages but in different environmental contexts may exhibit different-sized category biases.

In the present study, we test these two sets of hypotheses through a set of three analyses on data from early children's vocabularies to understand the possible origin of the noun bias in young children's word learning.

# Methods
In this section, we describe the broad methodological approach for all three analyses, leaving analysis-specific details to the subsequent sections.
All code is available at [REDACTED].

## Vocabulary data
```{r demogs}
#| fig.env = "figure", 
#| fig.pos = "t", 
#| fig.align = 'center', 
#| out.width = "240pt",
#| set.cap.width = T, 
#| num.cols.cap = 1, 
#| fig.cap = "Demographics of participants in all three analyses by country and language group. For Analysis 2, ranges indicate children's exposure proportions to English."

knitr::include_graphics("figs/demogs.png", error = FALSE)
```

We used data collected using Communicative Development Inventories (CDIs), which are parent-report vocabulary checklists [@marchmanMacArthurBatesCommunicativeDevelopment2023].
CDIs have been used by researchers in many contexts due to their ease of administration, their reliability and validity as a measure of language ability, and their availability in many language- and context-appropriate adaptations [@fensonMacArthurBatesCommunicativeDevelopment2007; @mayorStatisticalEstimateInfant2011].
We obtained CDI data from Wordbank [@frankWordbankOpenRepository2017], an open repository of CDI data that includes a few bilingual datasets.
These datasets contained vocabulary data for each child, as well as demographic information including the child's age and sex.
Each dataset also included language exposure values, standardised as percentages of exposure to each language.
An overview of participant demographics for all analyses is shown in Figure \ref{fig:demogs}.
We focused on production data for all analyses. 
<!--The data were retrieved using the `wordbankr` package [@braginskyWordbankrAccessingWordbank2022].-->

## Matching
Several covariates are known to affect early vocabularies, including the child's age and sex [@frankVariabilityConsistencyEarly2021, ch. 6]. 
To control for these effects, we conducted matching across different groups (e.g., monolinguals vs bilinguals, or bilinguals of different backgrounds), with the smallest group of interest as the focal group [i.e., common referent matching, @rassenSimultaneouslyAssessingIntended2011].
We matched for age and sex as covariates, as well as language exposure when comparing between bilinguals of different language combinations or countries.
We used cardinality matching as the matching method, as it provides better sample retention for small sample sizes [@fortinAppliedComparisonLargescale2021]. 
We verified the balance of the matched groups by evaluating the standardised mean differences for covariates after matching, using 0.1 as the threshold for balance.

## Bias estimation
We divided CDI items into four syntactic categories: nouns, predicates (verbs and adjectives), function words (closed-class words), and other (e.g., onomatopoeia and proper nouns); items in the other category were excluded from further analyses.
We then calculated the proportion of items known for each syntactic category (e.g., the number of nouns known divided by the total number of nouns on the CDI), as well as total vocabulary as a proportion of all CDI items.
<!--In this formulation, if a child's word learning were independent of syntactic category, the proportion values for each category would be equal to the total vocabulary proportion. 
If they exhibited a bias _towards_ a syntactic category, they should know more words in that category than expected, and vice versa for a bias _against_ a syntactic category.-->

We can thus calculate a group-level bias by estimating a generalised linear model predicting category proportion as a function of vocabulary proportion, and measuring the area between this curve and the diagonal.
If the curve lay above the diagonal, this area would be positive, indicating a positive bias, while if the curve lay below the diagonal, this area would be negative, indicating a negative bias.
Following previous work [@frankVariabilityConsistencyEarly2021, ch. 11], we used a third-order polynomial model constrained to pass through (0, 0) and (1, 1).
We also estimated confidence intervals by resampling 10,000 times with replacement for each group.

## Permutation testing
To test if groups differed in their syntactic category biases, we conducted permutation testing by shuffling group labels and re-estimating the biases.
For each analysis, we shuffled group labels 10,000 times and re-calculated the between-group differences in bias, allowing for an estimation of the $p$-value of the true observed between-group difference. 
We used a threshold of $\alpha = .05$ for significance.
All $p$-values were adjusted for multiple comparisons using Benjamini--Hochberg correction [@benjaminiControllingFalseDiscovery1995].

# Analysis 1: Varying language combinations
Our first analysis attempted to understand if children with different language combinations would exhibit different category biases.
In particular, we examined if bilinguals differed from monolinguals, and if different types of bilinguals (Mandarin--English and Malay--English) differed from each other, replicating @chaiExtralinguisticModulationEnglish2021.
This set of language combinations is particularly interesting because Mandarin has been suggested to have a positive verb bias and no noun bias, whereas English has a positive noun bias and a negative verb bias [e.g., @frankVariabilityConsistencyEarly2021, ch. 11], and Malay was hypothesised to be more similar to English than Mandarin [@chaiExtralinguisticModulationEnglish2021].
Hence, if syntactic category bias can be cross-linguistically modulated, it should be apparent in Mandarin--English bilinguals, whereas we do not expect the same modulation for Malay--English bilinguals.

## Dataset
```{r}
my_demog <- readRDS(here(INTERMEDIATE_LOC, "my_demog.rds"))
my_matched_cleaned <- readRDS(here(INTERMEDIATE_LOC, "my_matched_cleaned.rds"))
my_demog_matched <- my_matched_cleaned |> 
  select(data_id, age, sex, lang_group_fine) |> distinct()
```

<!--Can consider making a big ppt table for all 3 analyses?-->
The dataset for this analysis was contributed by @chaiExtralinguisticModulationEnglish2021.
It includes `r nrow(my_demog)` children (`r sum(my_demog$sex == "Male")` boys) from Malaysia aged `r floor(min(my_demog$age))`--`r ceiling(max(my_demog$age))` months.
We thresholded the language exposure values at 10% (i.e., participants with <10% exposure to a language were considered to not be exposed to that language), and divided the participants into groups based on the languages they were exposed to (some subset of Mandarin, Malay, and English).
Some groups were too small and were omitted (Mandarin--Malay bilinguals and Mandarin--Malay--English trilinguals); we used matching over the remaining groups, with Mandarin--English bilinguals as the focal group.[^1]
This resulted in a final sample of `r nrow(my_demog_matched)` children (`r sum(my_demog_matched$sex == "Male")` boys). 

[^1]: Note that the monolingual English group was in fact smaller than the Mandarin--English bilingual group, but matching to that group resulted in a much smaller final sample; hence, we matched to the second-smallest group and accepted a small amount of bias that would result from this decision.

## Results and discussion
```{r}
my_matched_models <- my_matched_cleaned |> 
  nest(data = -c(language, lex_class, lang_group)) |> 
  mutate(model = map(data, ~ langcog::clm(prop_class ~ I(prop_total^3) + 
                                            I(prop_total^2) + prop_total - 1, 
                                          data = .)),
         predictions = map(model, ~ broom:::augment.lm(., newdata = 
                                                         tibble(prop_total = pts))))

my_matched_preds <- my_matched_models |> 
  select(language, lex_class, lang_group, predictions) |> 
  unnest(predictions) |> 
  rename(prop_class = .fitted)
```

```{r my_prop}
#| fig.env = "figure", 
#| fig.pos = "t", 
#| fig.align = "center", 
#| fig.height = 5.5,
#| fig.width = 5.5,
#| out.width = "240pt",
#| set.cap.width = T, 
#| num.cols.cap = 1, 
#| fig.cap = "Syntactic category composition curves for each language and participant group from the Malaysian sample. Lines show model fits. The dashed line represents no bias. mon: monolinguals."

my_prop_plot <- make_prop_plot(my_matched_cleaned, my_matched_preds)
my_prop_plot
```

To illustrate our analytic approach, syntactic category composition curves are shown in Figure \ref{fig:my_prop}, reflecting the proportion of each syntactic category produced by each child as a function of the proportion of all items produced by the child. 
As found in previous work [@frankVariabilityConsistencyEarly2021, ch. 11], children exhibited a negative function word bias across all languages and groups.
Children also showed a positive noun bias in English and a positive predicate bias in Mandarin, while the size of the noun and predicate biases was close to zero for Malay.

```{r}
my_sampled_areas <- readRDS(here(INTERMEDIATE_LOC, "my_sampled_areas.rds"))

my_sampled_summary <- my_sampled_areas |> 
  filter(!is.na(area)) |> 
  group_by(language, lang_group, lex_class) |> 
  summarise(mean = mean(area),
            ci_lower = langcog::ci_lower(area),
            ci_upper = langcog::ci_upper(area))
```

```{r my_bias}
#| fig.env = "figure", 
#| fig.pos = "t", 
#| fig.align = "center", 
#| fig.height = 4.5,
#| fig.width = 6,
#| out.width = "240pt",
#| set.cap.width = T, 
#| num.cols.cap = 1, 
#| fig.cap = "Estimated syntactic category biases for each language and participant group from the Malaysian sample. Ranges indicate bootstrapped 95% confidence intervals. The dashed line represents no bias. mon: monolinguals."

my_bias_plot <- make_bias_plot(my_sampled_summary) +
  scale_colour_manual(values = c("#A9CD66", "#66CDB2", "#B766CD"),
                      guide = guide_legend(reverse = TRUE))
my_bias_plot
```

```{r}
# across
my_observed_areas <- my_matched_cleaned |> 
  nest(data = -c(language, lex_class, lang_group)) |> 
  mutate(area = map_dbl(data, poly_area)) |> 
  select(-data)

my_observed_areas_wide <- my_observed_areas |> 
  pivot_wider(names_from = lang_group,
              values_from = area) |> 
  mutate(engmsa_minus_mon = `eng-msa` - mon,
         engcmn_minus_mon = `eng-cmn` - mon,
         engcmn_minus_engmsa = `eng-cmn` - `eng-msa`)

my_observed_areas_diff <- my_observed_areas_wide |> 
  select(-`eng-msa`, -`eng-cmn`, -mon) |> 
  pivot_longer(cols = c("engmsa_minus_mon", "engcmn_minus_mon", "engcmn_minus_engmsa"), 
               names_to = "comparison", 
               values_to = "area_diff")

my_permuted_areas <- readRDS(here(INTERMEDIATE_LOC, "my_permuted_areas.rds"))

my_permuted_areas_wide <- my_permuted_areas |> 
  pivot_wider(names_from = lang_group,
              values_from = area) |> 
  mutate(engmsa_minus_mon = `eng-msa` - mon,
         engcmn_minus_mon = `eng-cmn` - mon,
         engcmn_minus_engmsa = `eng-cmn` - `eng-msa`)

my_permuted_areas_diff <- my_permuted_areas_wide |> 
  select(-`eng-msa`, -`eng-cmn`, -mon) |> 
  pivot_longer(cols = c("engmsa_minus_mon", "engcmn_minus_mon", "engcmn_minus_engmsa"), 
               names_to = "comparison", 
               values_to = "area_diff")

my_perm_test <- my_permuted_areas_diff |> 
  left_join(my_observed_areas_diff, 
            by = c("language", "lex_class", "comparison"),
            suffix = c("_perm", "_obs")) |> 
  mutate(obs_beats_perm = abs(area_diff_perm) - abs(area_diff_obs) > 0) |> 
  group_by(language, lex_class, comparison) |> 
  summarise(obs_p = sum(obs_beats_perm, na.rm = TRUE) / n(),
            .groups = "drop") |> 
  filter(!(language == "Malay" & comparison == "engcmn_minus_mon"),
         !(language == "Mandarin" & comparison == "engmsa_minus_mon"),
         !(language != "English" & comparison == "engcmn_minus_engmsa")) |> 
  arrange(comparison)
```

```{r}
# within
my_observed_areas_wide_within <- my_observed_areas |> 
  pivot_wider(names_from = language,
              values_from = area) |> 
  mutate(`eng-msa` = Malay - English,
         `eng-cmn` = Mandarin - English)

my_observed_areas_diff_within <- my_observed_areas_wide_within |> 
  select(-c(Malay, Mandarin, English)) |> 
  pivot_longer(cols = c("eng-msa", "eng-cmn"), 
               names_to = "comparison", 
               values_to = "area_diff")

my_permuted_areas_wide_within <- my_permuted_areas |> 
  pivot_wider(names_from = language,
              values_from = area) |> 
  mutate(`eng-msa` = Malay - English,
         `eng-cmn` = Mandarin - English)

my_permuted_areas_diff_within <- my_permuted_areas_wide_within |> 
  select(-c(Malay, Mandarin, English)) |> 
  pivot_longer(cols = c("eng-msa", "eng-cmn"), 
               names_to = "comparison", 
               values_to = "area_diff")

my_perm_test_within <- my_permuted_areas_diff_within |> 
  left_join(my_observed_areas_diff_within, 
            by = c("lang_group", "lex_class", "comparison"),
            suffix = c("_perm", "_obs")) |> 
  mutate(obs_beats_perm = abs(area_diff_perm) - abs(area_diff_obs) > 0) |> 
  group_by(lang_group, lex_class, comparison) |> 
  summarise(obs_p = sum(obs_beats_perm, na.rm = TRUE) / n(),
            .groups = "drop") |> 
  filter(lang_group == comparison) |> 
  arrange(comparison)
```

```{r}
my_perm_test_full <- bind_rows(my_perm_test, my_perm_test_within) |> 
  mutate(obs_p_adj = p.adjust(obs_p, "BH"))
```

To visualise the sizes of the syntactic category biases, Figure \ref{fig:my_bias} shows model estimates for each language and participant group.
We examined the following comparisons in our permutation test: bilinguals vs corresponding monolinguals, Mandarin--English vs Malay--English bilinguals, and English vs Mandarin/Malay within bilingual groups.
Although visually there appears to be variation across participant groups, there were not in fact any statistically significant differences across groups for any syntactic category in any language (all $p$ ≥ `r min(my_perm_test_full$obs_p_adj) |> papaja::apa_p()`).
In other words, participants with different language backgrounds exhibited similarly-sized category biases for any given language, and bilinguals did not differ in their category biases between their two languages.
This result corroborates and extends findings from @chaiExtralinguisticModulationEnglish2021, who did not find effects in production.[^2] 

[^2]: A similar analysis for comprehension data also did not reveal any significant differences between groups, even for the between-bilinguals condition found to have an effect by @chaiExtralinguisticModulationEnglish2021.

The lack of an effect is nonetheless surprising, since Mandarin and English have been found (in other studies) to have large differences in category bias sizes. 
There are a few possible reasons for this null finding.
First, the category bias effect sizes may have been influenced by language exposure.
Although we controlled for the effect of exposure statistically through matching, it is plausible that greater exposure to one language may entrain a larger modulation of category bias sizes in the other language for a bilingual.
Because children with different exposure distributions were collapsed together in this analysis, it was not possible to determine the contribution of language exposure to category bias sizes.
Second, it is possible that there was not enough power to find a significant effect due to the small sample size.
To address these issues, we shifted to a larger dataset in our second analysis, which allowed us to bin participants by language exposure.

# Analysis 2: Varying language exposures
In this analysis, we examined the effect of language exposure by binning children by language exposure proportions within a large sample of English--Spanish bilinguals.
If category bias were affected by cross-linguistic influence, we should see the largest modulation for children who receive the most exposure to another language.
In addition, across a bilingual child's two languages, we should see the biggest difference in bias sizes for children with the biggest imbalance in language exposure.

## Dataset
```{r}
us_demog <- readRDS(here(INTERMEDIATE_LOC, "us_demog.rds"))
us_matched_cleaned <- readRDS(here(INTERMEDIATE_LOC, "us_matched_cleaned.rds"))
us_demog_matched <- us_matched_cleaned |> 
  select(data_id, age, sex, lang_group) |> distinct()
```

The dataset for this analysis included data from @hoffDualLanguageExposure2012, @hoffWhatExplainsCorrelation2018, and @marchmanLanguagespecificNatureGrammatical2004 on English--Spanish bilingual children.
It includes `r nrow(us_demog)` children (`r sum(us_demog$sex == "Male")` boys) from the US aged `r floor(min(us_demog$age))`--`r ceiling(max(us_demog$age))` months.
We binned participants into five bins by language exposure, and matched participants across bins. 
This resulted in a final sample of `r nrow(us_demog_matched)` children (`r sum(us_demog_matched$sex == "Male")` boys). 

## Results and discussion
```{r}
us_sampled_areas <- readRDS(here(INTERMEDIATE_LOC, "us_sampled_areas.rds"))

us_sampled_summary <- us_sampled_areas |> 
  filter(!is.na(area)) |> 
  group_by(language, lang_group, lex_class) |> 
  summarise(mean = mean(area),
            ci_lower = langcog::ci_lower(area),
            ci_upper = langcog::ci_upper(area))
```

```{r us_bias}
#| fig.env = "figure", 
#| fig.pos = "t", 
#| fig.align = "center", 
#| fig.height = 5,
#| fig.width = 6,
#| out.width = "240pt",
#| set.cap.width = T, 
#| num.cols.cap = 1, 
#| fig.cap = "Estimated syntactic category biases for each language and English exposure proportion from the US sample. Ranges indicate bootstrapped 95% confidence intervals. The dashed line represents no bias."

us_bias_plot <- make_bias_plot(us_sampled_summary) +
  scale_colour_viridis_d(guide = guide_legend(reverse = TRUE))
us_bias_plot
```

```{r}
# across
us_observed_areas <- us_matched_cleaned |> 
  nest(data = -c(language, lex_class, lang_group)) |> 
  mutate(area = map_dbl(data, poly_area)) |> 
  select(-data)

us_observed_areas_wide <- us_observed_areas |> 
  pivot_wider(names_from = lang_group,
              values_from = area) |> 
  mutate(across(-c("lex_class", "language"), \(x) {x - `(80,100]`}))

us_observed_areas_diff <- us_observed_areas_wide |> 
  pivot_longer(cols = -c("lex_class", "language"), 
               names_to = "comparison", 
               values_to = "area_diff")

us_permuted_areas <- readRDS(here(INTERMEDIATE_LOC, "us_permuted_areas.rds"))

us_permuted_areas_wide <- us_permuted_areas |> 
  pivot_wider(names_from = lang_group,
              values_from = area) |> 
  # ungroup() |> 
  mutate(across(-c("lex_class", "language", "sample"), \(x) {x - `(80,100]`}))

us_permuted_areas_diff <- us_permuted_areas_wide |> 
  pivot_longer(cols = -c("lex_class", "language", "sample"), 
               names_to = "comparison", 
               values_to = "area_diff")

us_perm_test <- us_permuted_areas_diff |> 
  left_join(us_observed_areas_diff, 
            by = c("language", "lex_class", "comparison"),
            suffix = c("_perm", "_obs")) |> 
  mutate(obs_beats_perm = abs(area_diff_perm) - abs(area_diff_obs) > 0) |> 
  group_by(language, lex_class, comparison) |> 
  summarise(obs_p = sum(obs_beats_perm, na.rm = TRUE) / n(),
            .groups = "drop") |> 
  filter(comparison != "(80,100]") |> 
  arrange(comparison)
```

```{r}
# within
us_observed_areas_wide_within <- us_observed_areas |> 
  mutate(exp_eng = ifelse(language == "English",
                          as.character(lang_group),
                          case_when(
                            lang_group == "[0,20]" ~ "(80,100]",
                            lang_group == "(20,40]" ~ "(60,80]",
                            lang_group == "(40,60]" ~ "(40,60]",
                            lang_group == "(60,80]" ~ "(20,40]",
                            lang_group == "(80,100]" ~ "[0,20]",
                          ))) |> 
  select(-lang_group) |> 
  pivot_wider(names_from = language,
              values_from = area) |> 
  # ungroup() |> 
  mutate(spaeng = Spanish - English)

us_observed_areas_diff_within <- us_observed_areas_wide_within |> 
  select(-Spanish, -English) |> 
  pivot_longer(cols = -c("lex_class", "exp_eng"), 
               names_to = "comparison", 
               values_to = "area_diff")

us_permuted_areas_wide_within <- us_permuted_areas |> 
  mutate(exp_eng = ifelse(language == "English",
                          as.character(lang_group),
                          case_when(
                            lang_group == "[0,20]" ~ "(80,100]",
                            lang_group == "(20,40]" ~ "(60,80]",
                            lang_group == "(40,60]" ~ "(40,60]",
                            lang_group == "(60,80]" ~ "(20,40]",
                            lang_group == "(80,100]" ~ "[0,20]",
                          ))) |> 
  select(-lang_group) |> 
  pivot_wider(names_from = language,
              values_from = area) |> 
  # ungroup() |> 
  mutate(spaeng = Spanish - English)

us_permuted_areas_diff_within <- us_permuted_areas_wide_within |> 
  select(-Spanish, -English) |> 
  pivot_longer(cols = -c("lex_class", "exp_eng", "sample"), 
               names_to = "comparison", 
               values_to = "area_diff")

us_perm_test_within <- us_permuted_areas_diff_within |> 
  left_join(us_observed_areas_diff_within, 
            by = c("exp_eng", "lex_class", "comparison"),
            suffix = c("_perm", "_obs")) |> 
  mutate(obs_beats_perm = abs(area_diff_perm) - abs(area_diff_obs) > 0) |> 
  group_by(exp_eng, lex_class, comparison) |> 
  summarise(obs_p = sum(obs_beats_perm, na.rm = TRUE) / n(),
            .groups = "drop") |> 
  arrange(comparison)
```

```{r}
us_perm_test_full <- bind_rows(us_perm_test, us_perm_test_within) |> 
  mutate(obs_p_adj = p.adjust(obs_p, "BH"))
```

Figure \ref{fig:us_bias} shows model estimates for each language and participant group.
We examined the following comparisons in our permutation test: (80,100] vs other exposure bins for each language, and Spanish vs English for each corresponding exposure bin (i.e., [0,20] for English corresponds to (80,100] for Spanish).
Four comparisons survived the correction for multiple comparisons.
Children exposed to (80,100] percent English had more negative function word biases and more positive noun biases than children exposed to [0,20] percent English (both $p$ < .001).
Children exposed to (80,100] percent English also had more positive noun biases than children exposed to (20,40] percent English ($p$ = `r us_perm_test_full |> filter(language == "English", lex_class == "nouns", comparison == "(20,40]") |> pull(obs_p_adj) |> papaja::apa_p()`).
Finally, children exposed to (80,100] percent English had more negative function word biases in English than in Spanish ($p$ < .001).
Eight other comparisons were significant prior to correction but did not survive the correction (all $p$ within [`r us_perm_test_full |> filter(obs_p_adj > .05, obs_p < .05) |> pull(obs_p_adj) |> min() |> papaja::apa_p()`, `r us_perm_test_full |> filter(obs_p_adj > .05, obs_p < .05) |> pull(obs_p_adj) |> max() |> papaja::apa_p()`]).

As hypothesised, we found significant modulation of category biases in English for children exposed to more Spanish---i.e., the category biases of children exposed to >80% Spanish had _English_ category biases that were more like those of Spanish, in comparison to children exposed to ≤20% Spanish.
In addition, children with the biggest imbalance in language exposure (>80% English, ≤20% Spanish) showed the biggest difference in category biases across their two languages.
Interestingly, these effects were asymmetric---children exposed to more English did not show any modulation of their category biases in Spanish, and children exposed to mostly Spanish did not show a big difference in category biases across their languages.
One reason for this asymmetry may be the statuses of the two languages---in the US, English is the majority language while Spanish is a minority language.
The difference in language status may drive contextual differences in which these languages appear---for example, Spanish may be spoken more at home, while English may be spoken more in community settings.
Thus, the distributional properties of Spanish may not change regardless of language exposure, while those for English may shift from more idiolectal at lower exposure levels to more standard at higher exposure levels.
<!--Probably need a tigher linking hypothesis between contextual differences and observed category bias asymmetry-->
To understand the possible role of context, we turn to varying the environmental context in our third analysis.

# Analysis 3: Varying environmental contexts
In this analysis, we examine the effect of broad environmental context by comparing children who are acquiring the same pairs of languages but who are being raised in different countries.
If environmental factors (e.g., language status) affect category bias, we should observe differences in bias sizes for children in different countries, even if they are acquiring the same combination of languages, once factors such as age and language exposure are controlled for.

## Dataset
```{r}
ox_demog <- readRDS(here(INTERMEDIATE_LOC, "ox_demog.rds")) |> 
  filter(other_lang %in% c("German", "Germany",
                           "Dutch", "Netherlands",
                           "Spain", "Spanish"))
ox_matched_cleaned <- readRDS(here(INTERMEDIATE_LOC, "ox_matched_cleaned.rds"))
ox_demog_matched <- ox_matched_cleaned |> 
  select(data_id, age, sex, other_lang, lang_group) |> distinct()
```

The dataset for this analysis included data from @siowDoubleItVocabulary2023 on bilingual children in the UK and Continental Europe.
We chose a subset of language combinations that had data from both the UK and another European country: English--Dutch (UK/the Netherlands), English--German (UK/Germany), and English--Spanish (UK/Spain).
The data include `r nrow(ox_demog)` children (`r sum(ox_demog$sex == "Male")` boys) aged `r floor(min(ox_demog$age))`--`r ceiling(max(ox_demog$age))` months.
As in Analysis 1, we thresholded language exposure values at 10% and grouped participants by language combination and country of origin, performing matching within each language combination.
We also included the small set of UK monolingual English children for completeness.
This resulted in a final sample of `r nrow(ox_demog_matched)` children (`r sum(ox_demog_matched$sex == "Male")` boys). 

## Results and discussion
```{r}
ox_sampled_areas <- readRDS(here(INTERMEDIATE_LOC, "ox_sampled_areas.rds"))

ox_sampled_summary <- ox_sampled_areas |> 
  filter(!is.na(area)) |> 
  group_by(language, lang_group, lex_class) |> 
  summarise(mean = mean(area),
            ci_lower = langcog::ci_lower(area),
            ci_upper = langcog::ci_upper(area),
            .groups = "drop") |> 
  mutate(language = case_when(
    language == "Germany" ~ "German",
    language == "Netherlands" ~ "Dutch",
    language == "Spain" ~ "Spanish",
    .default = language
  ) |> fct_relevel(c("English", "Dutch", "German", "Spanish")) |> fct_rev(),
  lang_group = lang_group |> 
    fct_relevel(c("English", "Dutch", "Netherlands",
                  "German", "Germany", "Spanish", "Spain")) |> 
    fct_recode(`eng-gb` = "English", `nld-gb` = "Dutch", `nld-nd` = "Netherlands",
               `deu-gb` = "German", `deu-de` = "Germany", 
               `esp-gb` = "Spanish", `esp-sp` = "Spain"))
```

```{r ox_bias}
#| fig.env = "figure", 
#| fig.pos = "t", 
#| fig.align = "center", 
#| fig.height = 6.7,
#| fig.width = 6,
#| out.width = "240pt",
#| set.cap.width = T, 
#| num.cols.cap = 1, 
#| fig.cap = "Estimated syntactic category biases for each language and exposure proportion from the European sample. Ranges indicate bootstrapped 95% confidence intervals. The dashed line represents no bias. mon: monolinguals."

ox_bias_plot <- make_bias_plot(ox_sampled_summary |> 
                                 mutate(Country = ifelse(str_sub(lang_group, 5, 6) == "gb",
                                                         "UK", "EU") |> 
                                          fct_relevel("UK", "EU") |> fct_rev(),
                                        lang_group = str_sub(lang_group, 1, 3),
                                        lang_group = case_when(
                                          lang_group == "eng" ~ "mon",
                                          lang_group == "nld" ~ "eng-nld",
                                          lang_group == "deu" ~ "eng-deu",
                                          lang_group == "esp" ~ "eng-spa"
                                        ) |> 
                                          fct_relevel(c("mon", "eng-nld", 
                                                        "eng-deu", "eng-spa")) |> 
                                          fct_rev()),
                               shape_opt = Country) +
  scale_shape_manual(values = c(1, 16), 
                     guide = guide_legend(reverse = TRUE))
ox_bias_plot
```

```{r}
# English
ox_observed_areas <- ox_matched_cleaned |> 
  nest(data = -c(language, lex_class, lang_group)) |> 
  mutate(area = map_dbl(data, poly_area)) |> 
  select(-data)

ox_observed_areas_wide_eng <- ox_observed_areas |> 
  filter(language == "English") |> 
  pivot_wider(names_from = lang_group,
              values_from = area) |> 
  mutate(engdeu_de_vs_gb = Germany - German,
         engnld_nd_vs_gb = Netherlands - Dutch,
         engspa_es_vs_gb = Spain - Spanish,
         across(-c("lex_class", "language"), \(x) {x - English}))

ox_observed_areas_diff_eng <- ox_observed_areas_wide_eng |> 
  pivot_longer(cols = -c("lex_class", "language"), 
               names_to = "comparison", 
               values_to = "area_diff")

ox_permuted_areas_eng <- readRDS(here(INTERMEDIATE_LOC, "ox_permuted_areas_eng.rds"))

ox_permuted_areas_wide_eng <- ox_permuted_areas_eng |> 
  filter(language == "English") |> 
  pivot_wider(names_from = lang_group,
              values_from = area) |> 
  mutate(engdeu_de_vs_gb = Germany - German,
         engnld_nd_vs_gb = Netherlands - Dutch,
         engspa_es_vs_gb = Spain - Spanish,
         across(-c("lex_class", "language", "sample"), \(x) {x - English}))

ox_permuted_areas_diff_eng <- ox_permuted_areas_wide_eng |> 
  pivot_longer(cols = -c("lex_class", "language", "sample"), 
               names_to = "comparison", 
               values_to = "area_diff")

ox_perm_test_eng <- ox_permuted_areas_diff_eng |> 
  left_join(ox_observed_areas_diff_eng, 
            by = c("language", "lex_class", "comparison"),
            suffix = c("_perm", "_obs")) |> 
  mutate(obs_beats_perm = abs(area_diff_perm) - abs(area_diff_obs) > 0) |> 
  group_by(language, lex_class, comparison) |> 
  summarise(obs_p = sum(obs_beats_perm, na.rm = TRUE) / n(),
            .groups = "drop") |> 
  filter(comparison != "English") |> 
  arrange(comparison)
```

```{r}
# other language
ox_observed_areas_wide_oth <- ox_observed_areas |> 
  mutate(language = case_when(
    language == "Germany" ~ "German",
    language == "Netherlands" ~ "Dutch",
    language == "Spain" ~ "Spanish",
    .default = language
  ) |> fct_relevel(c("English", "Dutch", "German", "Spanish")) |> fct_rev(),
  lang_group = ifelse(lang_group %in% c("German", "Dutch", "Spanish"), "UK", lang_group)) |> 
  filter(language %in% c("German", "Dutch", "Spanish")) |> 
  pivot_wider(names_from = lang_group,
              values_from = area) |> 
  mutate(across(-c("lex_class", "language"), \(x) {x - UK}))

ox_observed_areas_diff_oth <- ox_observed_areas_wide_oth |> 
  pivot_longer(cols = -c("lex_class", "language"), 
               names_to = "comparison", 
               values_to = "area_diff") |> 
  filter(!is.na(area_diff), comparison != "UK")

ox_permuted_areas_oth <- readRDS(here(INTERMEDIATE_LOC, "ox_permuted_areas_oth.rds"))

ox_permuted_areas_wide_oth <- ox_permuted_areas_oth |> 
  # filter(language %in% c("German", "Dutch", "Spanish")) |> 
  mutate(lang_group = ifelse(language == lang_group, "UK", lang_group)) |> 
  filter(!is.na(area)) |> 
  pivot_wider(names_from = lang_group,
              values_from = area) |> 
  mutate(across(-c("lex_class", "language", "sample"), \(x) {x - UK}))

ox_permuted_areas_diff_oth <- ox_permuted_areas_wide_oth |> 
  pivot_longer(cols = -c("lex_class", "language", "sample"), 
               names_to = "comparison", 
               values_to = "area_diff") |> 
  filter(!is.na(area_diff), comparison != "UK")

ox_perm_test_oth <- ox_permuted_areas_diff_oth |> 
  left_join(ox_observed_areas_diff_oth, 
            by = c("language", "lex_class", "comparison"),
            suffix = c("_perm", "_obs")) |> 
  mutate(obs_beats_perm = abs(area_diff_perm) - abs(area_diff_obs) > 0) |> 
  group_by(language, lex_class, comparison) |> 
  summarise(obs_p = sum(obs_beats_perm, na.rm = TRUE) / n(),
            .groups = "drop") |> 
  filter(comparison != "UK") |> 
  arrange(comparison)
```

```{r}
ox_perm_test_full <- bind_rows(ox_perm_test_eng, ox_perm_test_oth) |> 
  mutate(obs_p_adj = p.adjust(obs_p, "BH"))
```

Figure \ref{fig:ox_bias} shows model estimates for each language and participant group.
We examined comparisons between children from different countries within each language combination<!-- (e.g., UK vs Germany for English--German children)-->.
For completeness, we also compared English category biases for all groups against the UK monolingual English group, although the imbalance in group size and other covariates means that these comparisons may be less reliable.
Only one comparison survived the correction for multiple comparisons: function words in German for children from the UK vs Germany ($p$ `r ox_perm_test_full |> filter(language == "German", lex_class == "function_words") |> pull(obs_p_adj) |> papaja::apa_p()`). 
Two other comparisons were significant prior to correction but did not survive the correction: function words in Spanish for children from the UK vs Spain ($p$ = `r ox_perm_test_full |> filter(language == "Spanish", lex_class == "function_words") |> pull(obs_p_adj) |> papaja::apa_p()`), and nouns in German for children from the UK vs Germany ($p$ = `r ox_perm_test_full |> filter(language == "German", lex_class == "nouns") |> pull(obs_p_adj) |> papaja::apa_p()`).

As hypothesised, we found an effect of environmental context, such that children acquiring English and German exhibited different function word biases depending on whether they were growing up in the UK or in Germany.
The lack of an effect for any other comparison may again be due to a lack of power, as is evidenced by the somewhat large confidence intervals. 
A larger sample may be able to provide narrower confidence intervals, and uncover smaller effects that the current sample cannot.
It may also be the case that the effect depends on the specific language combination, such that there is an interaction between the linguistic and contextual factors on category bias variation.

# General discussion
Across our three analyses, we found evidence that syntactic category biases could vary across a bilingual's two languages, and that these biases could be modulated cross-linguistically (Analysis 2), supporting H1c---category biases are affected by intra- and inter-language factors. 
We also found that category biases were sometimes influenced by children's environmental context (Analysis 3), supporting H2b---category biases are affected by contextual factors. 
Taken together, the supported hypotheses suggest that linguistic and contextual factors both play a role in shaping the syntactic composition of children's early vocabularies.
This finding also provides an imperative for language acquisition researchers to be more thorough and precise with their description of the language learning environment of their study populations, since background variables other than language may affect their language outcomes [see @titoneRethinkingMultilingualExperience2023].

Our results also suggested that factors affecting category biases were not uniform across language combinations (Analyses 1 and 3).
This observation is perhaps unsurprising---since some language pairs have very similar category bias sizes even for monolinguals, any cross-linguistic influence would not be apparent, whereas other language pairs have very divergent bias sizes, permitting the observation of cross-linguistic influence. 
This result also emphasises the importance of surveying a broader set of language combinations in bilingualism research, since some true effects may not be elicitable in particular language pairs. 
A majority of bilingualism research has focused on bilinguals acquiring English and another language (including the present work!), which does not comprehensively cover the possible relationships between a bilingual's two languages; a much broader scope of investigation would be necessary to understand the generalisability of various effects related to bilingualism.

Methodologically, the analytic method employed in the present work provided a means to directly investigate the over- or under-representation of syntactic categories in children's early vocabularies.
This method allowed for a measurement that has a closer link with the construct of interest---that is, whether particular syntactic categories are privileged in children's word learning processes---since the number of potentially learnable words is controlled for.
However, this approach also required the use of non-parametric statistics, since the bias sizes must be estimated from whole samples (rather than individual children); this requirement in turn meant that we had to control for covariates via matching (instead of direct modelling).
As matching is typically constrained by the subgroup with the smallest size, our approach may have limited the power of our analyses, as indeed was suggested by the large confidence intervals obtained.
Future work should involve larger sample sizes in order to improve the ability of such analyses to detect true effects, although we acknowledge that the task of collecting data from young bilinguals is often difficult as population sizes tend to be smaller than other potential populations of interest.

Nonetheless, the current set of analyses represent an attempt at disentangling a number of potential factors contributing to differential learning of words from different syntactic categories in young children, providing evidence that linguistic and contextual factors are both important to consider in language acquisition.
These results also show the importance of studying bilingual populations to understand learning processes theorised to underlie language acquisition in all contexts, since any such theory must be able to account for the simultaneous acquisition of multiple languages; the significance of this statement is underscored by the fact that language acquisition research on monolinguals is much more common than that on multilinguals, even though many more children grow up in multilingual rather than monolingual settings [@kiddHowDiverseChild2022].
In fact, studying bilinguals may afford approaches that are not possible with monolinguals, as evidenced by the present work.
We anticipate that an increasing emphasis on understudied language settings, combined with increasing statistical sophistication and increasing open science practices, will serve to improve the generalisability, accuracy, and rigour of our theories of language acquisition.

\newpage
# Acknowledgements
We would like to thank the data contributors as well as developers and maintainers of Wordbank, whose efforts towards open science have made this research possible.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
